{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##### `google colab` بارگذاری فایل در"
      ],
      "metadata": {
        "id": "cFClKAEFUibH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "collapsed": true,
        "id": "U4viGdyyQZxY",
        "outputId": "d17a01fd-76af-464e-b240-057a6853d937"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f34127fe-3ae7-432c-ba76-15660d9f53d8\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f34127fe-3ae7-432c-ba76-15660d9f53d8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle (3).json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle (3).json': b'{\"username\":\"reyhaneshirani\",\"key\":\"2ea6e2e3b5487aaac6cffa2faa8b71cc\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.upload()  # This will allow you to upload the kaggle.json file\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### .را از سیستم خود آپلود کنیم `kaggle.json` کدی که در بالا نوشته شده است به ما این امکان را میدهد تا فایل\n",
        "***"
      ],
      "metadata": {
        "id": "AoPpb65NUv1P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### انتقال فایل و تنظیم مجوز دسترسی"
      ],
      "metadata": {
        "id": "DswxEIHdU7O0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "PBIccTvAepxB"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### :با اجرای این سه خط کد\n",
        "##### ساخته میشود kaggle یک پوشه برای فایل‌های\n",
        "##### فایل به آن پوشه منتقل می‌شود\n",
        "##### مجوز دسترسی مناسب به فایل داده می‌شود\n",
        "***"
      ],
      "metadata": {
        "id": "xNBVsULyU34L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "!pip install kagglehub"
      ],
      "metadata": {
        "id": "W7W8FNRhfC7m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "##### کردن کتابخانه های مورد نیاز import\n"
      ],
      "metadata": {
        "id": "1I4XfIa_VInb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "path = kagglehub.dataset_download(\"manmandes/malimg\")\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0R9vCyXfTEb",
        "outputId": "38e2aa61-44a6-420c-c751-191b41c7baf5"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /kaggle/input/malimg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### دانلود دیتاسیت مورد نظر و چاپ کردن مسیر ذخیره سازی آن\n",
        "***"
      ],
      "metadata": {
        "id": "T7nLcnXZVQ_g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### کردن کتابخانه های مورد نیاز import"
      ],
      "metadata": {
        "id": "VIC0SmxaVUG3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "ROyWuP5HfpwV"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "##### دانلود دیتاسیت مورد نظر و چاپ کردن مسیر ذخیره سازی آن"
      ],
      "metadata": {
        "id": "3uMIJWeCVWYc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = os.path.join(path, \"malimg_dataset\")\n",
        "classes = os.listdir(dataset_path)"
      ],
      "metadata": {
        "id": "bHf36HZpfnrI"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***"
      ],
      "metadata": {
        "id": "kHE1iP-JVcVz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import imghdr\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for subfolder in ['train', 'test', 'val']:\n",
        "    folder_path = os.path.join(dataset_path, subfolder)\n",
        "    if os.path.isdir(folder_path):\n",
        "        for label_folder, _, files in os.walk(folder_path):  # عبور از پوشه‌ها و زیرپوشه‌ها\n",
        "            for file in files:\n",
        "                img_path = os.path.join(label_folder, file)\n",
        "                if os.path.isfile(img_path) and imghdr.what(img_path):  # چک کردن فایل‌های تصویری\n",
        "                    img = Image.open(img_path).convert('L')\n",
        "                    img = img.resize((64, 64))\n",
        "                    X.append(np.array(img))\n",
        "                    y.append(label_folder.split(\"/\")[-1])  # گرفتن نام پوشه به عنوان برچسب\n"
      ],
      "metadata": {
        "id": "AFBWBXXMl56d"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### :توضیحات کد\n",
        "##### در این قسمت از کد، تصاویر موجود در پوشه های مختلف بارگذاری میشوند و برای هر تصویر عملیات پیش پردازش انجام میگیرد\n",
        "##### لیسیتی برای ذخیره سازی داده های تصویری x\n",
        "##### لیستی برای ذخیره سازی برچسب های مربوط به هر تصویر y\n",
        "##### برای هر پوشه، زیرپوشه و وفایل های آن بررسی میشوند و برای هر فایل مسیر آن ساخته میشود\n",
        "##### برای هر فایل ابتدا بررسی میشود که آیا فایل تصویر است یا خیر سپس تصویر بارگذاری و به خاکستری تبدیل میشود\n",
        "##### اندازه تصویر به 64*64 تغییر پیدا میکند تا تصاویر اندازه های یکسانی داشته باشند\n",
        "##### اضافه مشیود x تصویر به آرایه تبدیل میشود و به لیست\n",
        "##### اضاغه میشود y نام پوشه ای که تصویر در آن قرار دارد که نمایانگر تصویر کلاس است به عنوان برچسب استخراج میشود و به لیست\n",
        "##### این قطعه کد به ما کمک میکند تا داده های تصویری را از پوشه های مختلف به همراه برچسب های آنها بارگذاری کرده و برای پردازش بعدی آماده کنیم\n",
        "\n",
        "***"
      ],
      "metadata": {
        "id": "LLuMB0a-VfHY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### آماده سازی داده ها برای مدل\n"
      ],
      "metadata": {
        "id": "Fl0Qf1spWAH7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(X)\n",
        "X = X.reshape(len(X), -1)  # Flattening the images into vectors\n",
        "encoder = LabelEncoder()\n",
        "y = encoder.fit_transform(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfI-i-nSh2hD",
        "outputId": "38f5a273-aa37-491a-d7e4-9f1b3e22e480"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X before flattening: (9339, 64, 64)\n",
            "Shape of X after flattening: (9339, 4096)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### تصاویر به آرایه عددی و سپس به بردار تبدیل میشوند تا در مدل قابل استفاده باشند\n",
        "##### برچسب ها که به صورت رشته هستند، به عدد تبدیل میشوند\n",
        "***"
      ],
      "metadata": {
        "id": "TbRVcxQoVr7P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### تقسیم داده ها به آموزش و تست"
      ],
      "metadata": {
        "id": "nmz2C73PWK94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "jqWpaW1igBVz"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "##### کردن کتابخانه های مورد نیاز import"
      ],
      "metadata": {
        "id": "VjcF7luaWMeB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "yiUgIo6zxtxH"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "### Naïve Bayes Model"
      ],
      "metadata": {
        "id": "Z5QaCS5SWQBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Naïve Bayes Model\n",
        "nb_model = GaussianNB()\n",
        "nb_model.fit(X_train, y_train)\n",
        "nb_y_pred = nb_model.predict(X_test)\n",
        "print(\"Naïve Bayes Classification Report:\")\n",
        "print(classification_report(y_test, nb_y_pred, target_names=encoder.classes_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "z1AtVFa4xcuq",
        "outputId": "cf13b3ed-2085-4ee7-eca3-6f5271162690"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naïve Bayes Classification Report:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "     Adialer.C       1.00      0.93      0.96        27\n",
            "     Agent.FYI       1.00      1.00      1.00        31\n",
            "     Allaple.A       0.99      0.99      0.99       601\n",
            "     Allaple.L       1.00      0.99      1.00       328\n",
            " Alueron.gen!J       0.94      1.00      0.97        33\n",
            "     Autorun.K       1.00      1.00      1.00        23\n",
            "       C2LOP.P       0.66      0.79      0.72        34\n",
            "   C2LOP.gen!g       0.90      0.86      0.88        43\n",
            "Dialplatform.B       1.00      0.97      0.99        36\n",
            "     Dontovo.A       1.00      1.00      1.00        43\n",
            "      Fakerean       1.00      0.98      0.99        66\n",
            " Instantaccess       1.00      0.97      0.98        86\n",
            "    Lolyda.AA1       0.81      0.97      0.89        36\n",
            "    Lolyda.AA2       1.00      0.77      0.87        31\n",
            "    Lolyda.AA3       1.00      0.92      0.96        36\n",
            "     Lolyda.AT       1.00      1.00      1.00        34\n",
            "   Malex.gen!J       1.00      0.96      0.98        24\n",
            " Obfuscator.AD       1.00      1.00      1.00        26\n",
            "      Rbot!gen       1.00      0.94      0.97        33\n",
            "    Skintrim.N       1.00      1.00      1.00         9\n",
            " Swizzor.gen!E       0.57      0.91      0.70        23\n",
            " Swizzor.gen!I       0.53      0.40      0.45        25\n",
            "         VB.AT       0.97      1.00      0.99        75\n",
            "    Wintrim.BX       1.00      1.00      1.00        13\n",
            "       Yuner.A       1.00      1.00      1.00       152\n",
            "\n",
            "      accuracy                           0.97      1868\n",
            "     macro avg       0.93      0.93      0.93      1868\n",
            "  weighted avg       0.97      0.97      0.97      1868\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### در این بخش یک مدل گوسیان برای دسته بندی داده ها استفاده میشود که مراحل این روش به شرح زیر است\n",
        "####  **ایجاد مدل**\n",
        "##### یک مدل ایجاد میشود که برای دسته بندی داده هایی که ویژگی آنها توزیع نرمال دارند، مناسب است  GussianNB() با استفاده از\n",
        "####  **آموزش مدل**\n",
        "##### انجام میشود fit() آموزش داده میشوند که این کار توسط تابع y_train و برچسب های آموزشی x_train مدل با استفاده از داده های آموزشی\n",
        "####  **پیش بینی با مدل**\n",
        "##### پیش بینی برچسب ها انجام میشود x_test پس از آموزش مدل، با استفاده از داده های آزمایشی   \n",
        "####  **ارزیابی مدل**\n",
        "##### برای ارزیابی مدل، گزارش دقت دسته بندی چاپ میشود که این گزارش، شامل معیار های دقت، صحت، بازخوانی و نمره برای هر کلاس است\n",
        "***"
      ],
      "metadata": {
        "id": "YDxz_kJwWVt1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### K-Nearest Neighbors (KNN) Model"
      ],
      "metadata": {
        "id": "7SswlEp7WeFw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# K-Nearest Neighbors (KNN) Model\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_model.fit(X_train, y_train)\n",
        "knn_y_pred = knn_model.predict(X_test)\n",
        "print(\"K-Nearest Neighbors (KNN) Classification Report:\")\n",
        "print(classification_report(y_test, knn_y_pred, target_names=encoder.classes_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "awJQO-r6zDWw",
        "outputId": "4f8293c4-3a6c-4966-e382-7595b06ae212"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "K-Nearest Neighbors (KNN) Classification Report:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "     Adialer.C       1.00      1.00      1.00        27\n",
            "     Agent.FYI       1.00      1.00      1.00        31\n",
            "     Allaple.A       0.86      1.00      0.93       601\n",
            "     Allaple.L       1.00      0.70      0.82       328\n",
            " Alueron.gen!J       1.00      1.00      1.00        33\n",
            "     Autorun.K       1.00      1.00      1.00        23\n",
            "       C2LOP.P       0.86      0.88      0.87        34\n",
            "   C2LOP.gen!g       0.97      0.91      0.94        43\n",
            "Dialplatform.B       1.00      0.97      0.99        36\n",
            "     Dontovo.A       0.98      1.00      0.99        43\n",
            "      Fakerean       1.00      0.98      0.99        66\n",
            " Instantaccess       1.00      1.00      1.00        86\n",
            "    Lolyda.AA1       1.00      0.97      0.99        36\n",
            "    Lolyda.AA2       1.00      1.00      1.00        31\n",
            "    Lolyda.AA3       1.00      0.97      0.99        36\n",
            "     Lolyda.AT       1.00      1.00      1.00        34\n",
            "   Malex.gen!J       0.92      0.96      0.94        24\n",
            " Obfuscator.AD       1.00      1.00      1.00        26\n",
            "      Rbot!gen       0.94      1.00      0.97        33\n",
            "    Skintrim.N       0.90      1.00      0.95         9\n",
            " Swizzor.gen!E       0.63      0.74      0.68        23\n",
            " Swizzor.gen!I       0.68      0.52      0.59        25\n",
            "         VB.AT       1.00      1.00      1.00        75\n",
            "    Wintrim.BX       0.72      1.00      0.84        13\n",
            "       Yuner.A       1.00      1.00      1.00       152\n",
            "\n",
            "      accuracy                           0.93      1868\n",
            "     macro avg       0.94      0.94      0.94      1868\n",
            "  weighted avg       0.94      0.93      0.93      1868\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### برای دسته بندی داده ها استفاده میشود که مراحل این روش به شرح زیر استKNN در این بخش از مدل\n",
        "####  **ایجاد مدل**\n",
        "##### به این معنی است که پیش بینی برای هرنمونه براساس 5 نزدیکترین همسایه آن انجام میشود n_neighbors=5ایجاد میشود. دراین مدل، پارامترKNN یک مدل\n",
        "####  **آموزش مدل**\n",
        "##### انجام میشود fit() آموزش داده میشوند که این کار توسط تابع y_train و برچسب های آموزشی x_train مدل با استفاده از داده های آموزشی\n",
        "####  **پیش بینی با مدل**\n",
        "##### ذخیره میشودknn_y_pred انجام میشود. پیش بینی متغیرها در x_test پس از آموزش مدل، پیش بینی برچسب ها برای داده آموزشی\n",
        "####  **ارزیابی مدل**\n",
        "##### برای ارزیابی مدل، گزارش دقت دسته بندی چاپ میشود که این گزارش، شامل معیار های دقت، صحت، بازخوانی و نمره برای هر کلاس است\n",
        "***"
      ],
      "metadata": {
        "id": "mo5G3WSAWhGU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest Model"
      ],
      "metadata": {
        "id": "z-ChJ_prWop5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest Model\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "rf_y_pred = rf_model.predict(X_test)\n",
        "print(\"Random Forest Classification Report:\")\n",
        "print(classification_report(y_test, rf_y_pred, target_names=encoder.classes_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "41AAxqFczJJc",
        "outputId": "e983c0d7-af29-4dc0-e818-4ec62bbd9267"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Classification Report:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "     Adialer.C       1.00      1.00      1.00        27\n",
            "     Agent.FYI       1.00      1.00      1.00        31\n",
            "     Allaple.A       1.00      1.00      1.00       601\n",
            "     Allaple.L       1.00      1.00      1.00       328\n",
            " Alueron.gen!J       1.00      1.00      1.00        33\n",
            "     Autorun.K       1.00      1.00      1.00        23\n",
            "       C2LOP.P       0.86      0.88      0.87        34\n",
            "   C2LOP.gen!g       0.87      0.93      0.90        43\n",
            "Dialplatform.B       1.00      0.97      0.99        36\n",
            "     Dontovo.A       0.98      1.00      0.99        43\n",
            "      Fakerean       1.00      0.98      0.99        66\n",
            " Instantaccess       1.00      1.00      1.00        86\n",
            "    Lolyda.AA1       1.00      1.00      1.00        36\n",
            "    Lolyda.AA2       1.00      1.00      1.00        31\n",
            "    Lolyda.AA3       1.00      0.94      0.97        36\n",
            "     Lolyda.AT       1.00      1.00      1.00        34\n",
            "   Malex.gen!J       1.00      0.92      0.96        24\n",
            " Obfuscator.AD       1.00      1.00      1.00        26\n",
            "      Rbot!gen       1.00      1.00      1.00        33\n",
            "    Skintrim.N       1.00      1.00      1.00         9\n",
            " Swizzor.gen!E       0.65      0.65      0.65        23\n",
            " Swizzor.gen!I       0.64      0.56      0.60        25\n",
            "         VB.AT       1.00      1.00      1.00        75\n",
            "    Wintrim.BX       0.93      1.00      0.96        13\n",
            "       Yuner.A       1.00      1.00      1.00       152\n",
            "\n",
            "      accuracy                           0.98      1868\n",
            "     macro avg       0.96      0.95      0.95      1868\n",
            "  weighted avg       0.98      0.98      0.98      1868\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### برای دسته بندی داده ها استفاده میشود که مراحل آن به شرح زیر استRandom Forest در این بخش از مدل\n",
        "####  **ایجاد مدل**\n",
        "##### به این معنی است که جنگل تصادفی از 100 درخت تصمیم ساخته شده است n_estimators=100 یک مدل ایجاد میشود که\n",
        "####  **آموزش مدل**\n",
        "##### انجام میشود fit() آموزش داده میشوند که این کار توسط تابع y_train و برچسب های آموزشی x_train مدل با استفاده از داده های آموزشی\n",
        "####  **پیش بینی با مدل**\n",
        "##### ذخیره میشود rf_y_pred انجام میشود. پیش بینی متغیرها در x_test پس از آموزش مدل، پیش بینی برچسب ها برای داده آموزشی\n",
        "####  **ارزیابی با مدل**\n",
        "##### برای ارزیابی مدل، گزارش دقت دسته بندی چاپ میشود که این گزارش، شامل معیار های دقت، صحت، بازخوانی و نمره برای هر کلاس است\n",
        "***"
      ],
      "metadata": {
        "id": "yNioNdgCWqNz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression Model"
      ],
      "metadata": {
        "id": "DBcN3uYbWwdk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression Model\n",
        "lr_model = LogisticRegression(max_iter=1000)\n",
        "lr_model.fit(X_train, y_train)\n",
        "lr_y_pred = lr_model.predict(X_test)\n",
        "print(\"Logistic Regression Classification Report:\")\n",
        "print(classification_report(y_test, lr_y_pred, target_names=encoder.classes_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "DX_OtDFszKja",
        "outputId": "9170dd03-8688-4469-b6ef-3c523dcd4b7f"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Classification Report:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "     Adialer.C       1.00      1.00      1.00        27\n",
            "     Agent.FYI       1.00      1.00      1.00        31\n",
            "     Allaple.A       1.00      1.00      1.00       601\n",
            "     Allaple.L       1.00      1.00      1.00       328\n",
            " Alueron.gen!J       0.92      1.00      0.96        33\n",
            "     Autorun.K       1.00      1.00      1.00        23\n",
            "       C2LOP.P       0.76      0.74      0.75        34\n",
            "   C2LOP.gen!g       0.78      0.84      0.81        43\n",
            "Dialplatform.B       1.00      0.97      0.99        36\n",
            "     Dontovo.A       1.00      1.00      1.00        43\n",
            "      Fakerean       1.00      0.98      0.99        66\n",
            " Instantaccess       1.00      1.00      1.00        86\n",
            "    Lolyda.AA1       1.00      0.97      0.99        36\n",
            "    Lolyda.AA2       1.00      1.00      1.00        31\n",
            "    Lolyda.AA3       0.97      0.97      0.97        36\n",
            "     Lolyda.AT       1.00      1.00      1.00        34\n",
            "   Malex.gen!J       0.96      0.96      0.96        24\n",
            " Obfuscator.AD       1.00      1.00      1.00        26\n",
            "      Rbot!gen       1.00      1.00      1.00        33\n",
            "    Skintrim.N       1.00      1.00      1.00         9\n",
            " Swizzor.gen!E       0.54      0.61      0.57        23\n",
            " Swizzor.gen!I       0.44      0.28      0.34        25\n",
            "         VB.AT       1.00      0.99      0.99        75\n",
            "    Wintrim.BX       0.76      1.00      0.87        13\n",
            "       Yuner.A       1.00      1.00      1.00       152\n",
            "\n",
            "      accuracy                           0.97      1868\n",
            "     macro avg       0.92      0.93      0.93      1868\n",
            "  weighted avg       0.97      0.97      0.97      1868\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### برای دسته بندی داده ها استفاده میشود که مراحل آن به شرح زیر استlogic regression در این بخش از مدل\n",
        "####  **ایجاد مدل**\n",
        "##### به این معنی است که مدل حداکثر 1000 بار تلاش میکند تا  الگوریتم خود را بهینه کند max_iter=1000 یک مدل ایجاد میشود که\n",
        "####  **آموزش مدل**\n",
        "##### انجام میشود fit() آموزش داده میشوند که این کار توسط تابع y_train و برچسب های آموزشی x_train مدل با استفاده از داده های آموزشی\n",
        "####  **پیش بینی با مدل**\n",
        "##### ذخیره میشود lr_y_pred انجام میشود. پیش بینی متغیرها در x_test پس از آموزش مدل، پیش بینی برچسب ها برای داده آموزشی\n",
        "####  **ارزیابی با مدل**\n",
        "##### برای ارزیابی مدل، گزارش دقت دسته بندی چاپ میشود که این گزارش، شامل معیار های دقت، صحت، بازخوانی و نمره برای هر کلاس است"
      ],
      "metadata": {
        "id": "7NoGB2SJWx8W"
      }
    }
  ]
}